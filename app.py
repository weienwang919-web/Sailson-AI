import os
import sys
import datetime
import time
import logging
import pandas as pd
from io import BytesIO
from PIL import Image
from flask import Flask, render_template, request, jsonify, redirect, url_for, session, send_file
import google.generativeai as genai
from apify_client import ApifyClient
from dotenv import load_dotenv
from openpyxl import Workbook
from openpyxl.styles import Font, Alignment, PatternFill
from openpyxl.utils.dataframe import dataframe_to_rows

# åŠ è½½ .env æ–‡ä»¶
load_dotenv()

# ============================================
# æ—¥å¿—é…ç½® - ç¡®ä¿è¾“å‡ºåˆ° stdout
# ============================================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger(__name__)

# ============================================
# ç¯å¢ƒé…ç½® - ä¼˜åŒ–ç‰ˆ
# ============================================

# æ¸…é™¤ä»£ç†è®¾ç½®ï¼ˆäº‘ç«¯ç¯å¢ƒä¸éœ€è¦ä»£ç†ï¼‰
for proxy_var in ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy']:
    if proxy_var in os.environ:
        del os.environ[proxy_var]
        logger.info(f"ğŸ§¹ å·²æ¸…é™¤ä»£ç†è®¾ç½®: {proxy_var}")

# åŠ è½½ç¯å¢ƒå˜é‡
GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY')
APIFY_TOKEN = os.environ.get('APIFY_TOKEN')
PORT = int(os.environ.get('PORT', 5001))

# å¯åŠ¨æ—¶è¾“å‡ºé…ç½®çŠ¶æ€
logger.info("=" * 60)
logger.info("ğŸš€ Sailson AI å·¥ä½œå°å¯åŠ¨ä¸­...")
logger.info(f"ğŸ”‘ GOOGLE_API_KEY: {'âœ… å·²é…ç½®' if GOOGLE_API_KEY else 'âŒ æœªé…ç½®'}")
logger.info(f"ğŸ”‘ APIFY_TOKEN: {'âœ… å·²é…ç½®' if APIFY_TOKEN else 'âŒ æœªé…ç½®'}")
logger.info(f"ğŸŒ PORT: {PORT}")
logger.info(f"ğŸ Python ç‰ˆæœ¬: {sys.version}")
logger.info("=" * 60)

# åˆå§‹åŒ– AI å¼•æ“
if GOOGLE_API_KEY:
    try:
        genai.configure(api_key=GOOGLE_API_KEY)
        logger.info("âœ… Google Gemini API åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ Google Gemini API åˆå§‹åŒ–å¤±è´¥: {e}")
else:
    logger.warning("âš ï¸ è­¦å‘Š: GOOGLE_API_KEY æœªé…ç½®ï¼ŒAI åŠŸèƒ½å°†ä¸å¯ç”¨")

# åˆå§‹åŒ–çˆ¬è™«å¼•æ“
if APIFY_TOKEN:
    try:
        apify_client = ApifyClient(APIFY_TOKEN)
        logger.info("âœ… Apify å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ Apify å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        apify_client = None
else:
    logger.warning("âš ï¸ è­¦å‘Š: APIFY_TOKEN æœªé…ç½®ï¼Œçˆ¬è™«åŠŸèƒ½å°†ä¸å¯ç”¨")
    apify_client = None

# Flask åº”ç”¨åˆå§‹åŒ–
app = Flask(__name__)
app.secret_key = os.environ.get('SECRET_KEY', 'sailson_secure_key')
HISTORY_DB = []
LATEST_ANALYSIS_RESULTS = {}  # å­˜å‚¨æœ€æ–°çš„åˆ†æç»“æœï¼Œç”¨äºå¯¼å‡º

# ============================================
# æ ¸å¿ƒå·¥å…·å‡½æ•°
# ============================================

def call_gemini(prompt, image=None, timeout=60):
    """è°ƒç”¨ Google Gemini API"""
    if not GOOGLE_API_KEY:
        error_msg = "âŒ é”™è¯¯ï¼šGOOGLE_API_KEY æœªé…ç½®"
        logger.error(error_msg)
        return error_msg

    model_name = 'gemini-2.5-flash'

    try:
        logger.info(f"ğŸ¤– æ­£åœ¨è°ƒç”¨ Gemini æ¨¡å‹: {model_name}")
        logger.info(f"ğŸ“ Prompt é•¿åº¦: {len(prompt)} å­—ç¬¦")

        model = genai.GenerativeModel(model_name)
        response = model.generate_content(prompt)

        result = response.text
        logger.info(f"âœ… Gemini è°ƒç”¨æˆåŠŸï¼Œè¿”å› {len(result)} å­—ç¬¦")
        return result

    except Exception as e:
        error_msg = f"âš ï¸ Gemini API è°ƒç”¨å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        import traceback
        traceback.print_exc()
        return error_msg


def process_uploaded_file(file):
    """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆå›¾ç‰‡æˆ–è¡¨æ ¼ï¼‰"""
    try:
        fname = file.filename.lower()
        logger.info(f"ğŸ“ å¤„ç†æ–‡ä»¶: {fname}")

        if fname.endswith(('.png', '.jpg', '.jpeg', '.webp')):
            logger.info("ğŸ–¼ï¸ è¯†åˆ«ä¸ºå›¾ç‰‡æ–‡ä»¶")
            return "IMAGE", Image.open(file)

        if fname.endswith(('.xlsx', '.csv')):
            logger.info("ğŸ“Š è¯†åˆ«ä¸ºè¡¨æ ¼æ–‡ä»¶")
            if fname.endswith('.csv'):
                df = pd.read_csv(file)
            else:
                df = pd.read_excel(file)
            return "TEXT", df.to_string(index=False, max_rows=50)

        return "ERROR", "ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼"

    except Exception as e:
        error_msg = f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}"
        logger.info(f"âŒ {error_msg}")
        return "ERROR", error_msg


def save_history(title, result, type_tag):
    """ä¿å­˜åˆ°å†å²è®°å½•"""
    record = {
        'id': len(HISTORY_DB) + 1,
        'title': f"{title} [{datetime.datetime.now().strftime('%H:%M')}]",
        'result': result,
        'type': type_tag
    }
    HISTORY_DB.append(record)
    logger.info(f"ğŸ’¾ å·²ä¿å­˜å†å²è®°å½• #{record['id']}: {title}")


def call_veo_api(prompt):
    """è°ƒç”¨ Google Veo APIï¼ˆæ¨¡æ‹Ÿï¼‰"""
    logger.info(f"ğŸ¬ æ¨¡æ‹Ÿ Veo API è°ƒç”¨: {prompt[:50]}...")
    time.sleep(3)
    return "https://cdn.pixabay.com/video/2023/10/22/186115-877653483_large.mp4"

# ============================================
# åŸºç¡€è·¯ç”±
# ============================================

@app.route('/login', methods=['GET', 'POST'])
def login():
    """ç™»å½•é¡µé¢"""
    if request.method == 'POST':
        username = request.form.get('username')
        password = request.form.get('password')

        if username == 'admin' and password == '123456':
            session['logged_in'] = True
            session['session_id'] = f"{username}_{int(time.time())}"
            logger.info(f"âœ… ç”¨æˆ·ç™»å½•æˆåŠŸ: {username}")
            return redirect(url_for('home'))
        else:
            logger.info(f"âŒ ç™»å½•å¤±è´¥: {username}")

    return render_template('login.html')


@app.route('/logout')
def logout():
    """ç™»å‡º"""
    session.pop('logged_in', None)
    logger.info("ğŸ‘‹ ç”¨æˆ·å·²ç™»å‡º")
    return redirect(url_for('login'))


@app.route('/')
def home():
    """é¦–é¡µ"""
    if not session.get('logged_in'):
        return redirect(url_for('login'))
    return render_template('index.html')


@app.route('/debug')
def debug_page():
    """è°ƒè¯•é¡µé¢"""
    if not session.get('logged_in'):
        return redirect(url_for('login'))

    debug_info = {
        "status": "Online",
        "gemini_key": bool(GOOGLE_API_KEY),
        "apify_key": bool(APIFY_TOKEN),
        "port": PORT,
        "history_count": len(HISTORY_DB)
    }
    logger.info(f"ğŸ” è°ƒè¯•ä¿¡æ¯: {debug_info}")
    return jsonify(debug_info)


@app.route('/health')
def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹ - ç”¨äº Render ç›‘æ§"""
    return jsonify({"status": "ok", "service": "Sailson AI"}), 200

# ============================================
# åŠŸèƒ½ 1: èˆ†æƒ…åˆ†æ
# ============================================

@app.route('/sentiment-tool')
def sentiment_tool():
    """èˆ†æƒ…åˆ†æå·¥å…·é¡µé¢"""
    if not session.get('logged_in'):
        return redirect(url_for('login'))
    return render_template('analysis.html')


@app.route('/analyze', methods=['POST'])
def analyze():
    """èˆ†æƒ…åˆ†æ API"""
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“¥ æ”¶åˆ°èˆ†æƒ…åˆ†æè¯·æ±‚")
    logger.info(f"ğŸ”‘ GOOGLE_API_KEY: {'âœ…' if GOOGLE_API_KEY else 'âŒ'}")
    logger.info(f"ğŸ”‘ APIFY_TOKEN: {'âœ…' if APIFY_TOKEN else 'âŒ'}")

    url = request.form.get('url')
    file = request.files.get('file')
    content = ""
    img = None
    source_title = "æœªçŸ¥"

    try:
        # è·¯å¾„ A: æ–‡ä»¶ä¸Šä¼ åˆ†æ
        if file:
            logger.info(f"ğŸ“ å¤„ç†æ¨¡å¼: æ–‡ä»¶ä¸Šä¼ ")
            mode, res = process_uploaded_file(file)

            if mode == "ERROR":
                logger.info(f"âŒ æ–‡ä»¶å¤„ç†å¤±è´¥: {res}")
                return jsonify({'result': f"âŒ {res}"})

            if mode == "IMAGE":
                img = res
                content = "åˆ†æå›¾ç‰‡ä¸­çš„åé¦ˆå†…å®¹"
                logger.info("ğŸ–¼ï¸ å›¾ç‰‡æ¨¡å¼")
            else:
                content = res
                logger.info("ğŸ“Š è¡¨æ ¼æ¨¡å¼")

            source_title = f"æ–‡ä»¶: {file.filename[:15]}"

        # è·¯å¾„ B: ç¤¾äº¤åª’ä½“é“¾æ¥æŠ“å–åˆ†æ
        elif url:
            logger.info(f"ğŸ”— å¤„ç†æ¨¡å¼: é“¾æ¥çˆ¬å–")
            logger.info(f"ğŸ”— ç›®æ ‡ URL: {url}")

            if not apify_client:
                error_msg = "âŒ é”™è¯¯ï¼šAPIFY_TOKEN æœªé…ç½®ï¼Œæ— æ³•ä½¿ç”¨çˆ¬è™«åŠŸèƒ½"
                logger.error(error_msg)
                return jsonify({'result': error_msg})

            try:
                logger.info(f"ğŸ•µï¸ å¯åŠ¨ Apify çˆ¬è™«...")
                run_input = {
                    "startUrls": [{"url": url}],
                    "resultsLimit": 1000,  # è¿™æ˜¯æ­£ç¡®çš„å‚æ•°å
                    "maxComments": 1000,
                    "maxPostCount": 1,
                    "maxCommentsPerPost": 1000,
                    "maxRepliesPerComment": 0,  # ä¸æŠ“å–å›å¤ï¼ŒåªæŠ“å–ä¸»è¯„è®º
                    "scrapeCommentReplies": False  # ä¸æŠ“å–å›å¤
                }

                logger.info(f"ğŸ“‹ çˆ¬è™«é…ç½®: {run_input}")

                # ä½¿ç”¨ start() å¯åŠ¨çˆ¬è™«
                run = apify_client.actor("apify/facebook-comments-scraper").start(run_input=run_input)
                logger.info(f"âœ… çˆ¬è™«ä»»åŠ¡å·²å¯åŠ¨ï¼ŒRun ID: {run['id']}")

                # ç­‰å¾…çˆ¬è™«å®Œæˆï¼ˆæ­£ç¡®çš„å‚æ•°åï¼‰
                logger.info("â³ ç­‰å¾…çˆ¬è™«å®Œæˆ...")
                run = apify_client.run(run['id']).wait_for_finish(wait_secs=180)  # å¢åŠ åˆ°180ç§’
                logger.info(f"âœ… çˆ¬è™«ä»»åŠ¡å®Œæˆï¼ŒçŠ¶æ€: {run['status']}")

                if run['status'] != 'SUCCEEDED':
                    error_msg = f"âŒ çˆ¬è™«ä»»åŠ¡å¤±è´¥ï¼ŒçŠ¶æ€: {run['status']}"
                    logger.error(error_msg)
                    return jsonify({'result': error_msg})

                # è·å–æ‰€æœ‰æ•°æ®ï¼ˆå¯èƒ½éœ€è¦åˆ†é¡µï¼‰
                dataset_client = apify_client.dataset(run["defaultDatasetId"])
                items = []
                offset = 0
                limit = 1000

                while True:
                    batch = dataset_client.list_items(offset=offset, limit=limit).items
                    if not batch:
                        break
                    items.extend(batch)
                    logger.info(f"ğŸ“¦ å·²è·å– {len(items)} æ¡æ•°æ®ï¼ˆæœ¬æ‰¹æ¬¡: {len(batch)}ï¼‰...")
                    if len(batch) < limit:
                        break
                    offset += limit

                logger.info(f"âœ… æ€»å…±è·å–åˆ° {len(items)} æ¡æ•°æ®")

                # è°ƒè¯•ï¼šæŸ¥çœ‹ run çš„è¯¦ç»†ä¿¡æ¯
                logger.info(f"ğŸ” Run è¯¦æƒ…: status={run.get('status')}, stats={run.get('stats')}")

                if not items:
                    warning_msg = "âš ï¸ æŠ“å–æˆåŠŸä½†æœªå‘ç°å…¬å¼€è¯„è®ºï¼Œè¯·æ£€æŸ¥é“¾æ¥æƒé™"
                    logger.warning(warning_msg)
                    return jsonify({'result': warning_msg})

                # åˆ†æ‰¹å¤„ç†è¯„è®ºï¼ˆæ¯æ‰¹ 50 æ¡ï¼‰
                batch_size = 50
                all_results = []

                logger.info(f"ğŸ“Š å¼€å§‹åˆ†æ‰¹åˆ†æï¼Œæ¯æ‰¹ {batch_size} æ¡...")

                for i in range(0, len(items), batch_size):
                    batch = items[i:i+batch_size]
                    batch_num = i // batch_size + 1
                    total_batches = (len(items) + batch_size - 1) // batch_size

                    logger.info(f"ğŸ”„ å¤„ç†ç¬¬ {batch_num}/{total_batches} æ‰¹ï¼ˆ{len(batch)} æ¡è¯„è®ºï¼‰...")

                    batch_content = "\n".join([f"ç”¨æˆ·{j}: {it.get('text', '')}" for j, it in enumerate(batch)])

                    # ç®€åŒ–çš„ Promptï¼Œåªåšåˆ†ç±»
                    batch_prompt = f"""
Analyze these comments and categorize them. Output ONLY a JSON array.

Comments:
{batch_content}

Categories (Chinese only):
1. å¤–æŒ‚ä½œå¼Š - hackers, cheating
2. æ¸¸æˆä¼˜åŒ– - lag, crashes
3. æ¸¸æˆBug - glitches, errors
4. å……å€¼é€€æ¬¾ - payment issues
5. æ–°æ¨¡å¼/åœ°å›¾/å¹³è¡¡æ€§å»ºè®® - new content requests
6. å…¶ä»– - spam, praise

Output format (JSON array only, no markdown):
[
  {{
    "text": "comment text",
    "category": "å¤–æŒ‚ä½œå¼Š",
    "sentiment": "è´Ÿé¢",
    "language": "è‹±è¯­",
    "analysis": "è¯¦ç»†åˆ†æå†…å®¹"
  }},
  ...
]

IMPORTANT:
- Output ONLY valid JSON array
- Skip "å…¶ä»–" category
- Use Chinese for category, sentiment, language, and analysis
- Language options: è‹±è¯­, ä¸­æ–‡, æ—¥è¯­, éŸ©è¯­, æ³°è¯­, è¶Šå—è¯­, å…¶ä»–
- Analysis requirements:
  * For short comments (< 30 chars): One sentence summary (15-20 Chinese characters)
  * For medium/long comments (>= 30 chars): Detailed analysis (40-50 Chinese characters)
  * Include: main issue, player emotion, key details
"""

                    result = call_gemini(batch_prompt, timeout=60)

                    # è§£æ JSON ç»“æœ
                    try:
                        import json
                        import re
                        # æ¸…ç†å¯èƒ½çš„ markdown æ ‡è®°
                        clean_result = re.sub(r'```json\s*|\s*```', '', result).strip()
                        batch_data = json.loads(clean_result)
                        all_results.extend(batch_data)
                        logger.info(f"âœ… ç¬¬ {batch_num} æ‰¹å®Œæˆï¼Œè·å¾— {len(batch_data)} æ¡æœ‰æ•ˆç»“æœ")
                    except Exception as e:
                        logger.error(f"âŒ ç¬¬ {batch_num} æ‰¹è§£æå¤±è´¥: {e}")
                        continue

                # ç”Ÿæˆ HTML è¡¨æ ¼
                logger.info(f"ğŸ“ ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šï¼Œå…± {len(all_results)} æ¡æœ‰æ•ˆè¯„è®º...")

                # æŒ‰åˆ†ç±»æ’åº
                category_order = ["å¤–æŒ‚ä½œå¼Š", "æ¸¸æˆä¼˜åŒ–", "æ¸¸æˆBug", "å……å€¼é€€æ¬¾", "æ–°æ¨¡å¼/åœ°å›¾/å¹³è¡¡æ€§å»ºè®®"]
                all_results.sort(key=lambda x: category_order.index(x.get('category', 'å…¶ä»–')) if x.get('category') in category_order else 999)

                # ç”Ÿæˆ HTML
                html_rows = []
                for idx, item in enumerate(all_results, 1):
                    html_rows.append(f"""
                    <tr>
                        <td>{idx}</td>
                        <td style="white-space: pre-wrap; word-break: break-word;">{item.get('text', '')}</td>
                        <td><strong>{item.get('category', '')}</strong></td>
                        <td>{item.get('sentiment', '')}</td>
                        <td>{item.get('language', '')}</td>
                        <td style="white-space: pre-wrap; word-break: break-word;">{item.get('analysis', '')}</td>
                    </tr>
                    """)

                result = f"""
                <table class="table table-hover">
                    <thead>
                        <tr>
                            <th style="width:40px;">#</th>
                            <th style="width:25%;">åŸå§‹è¯„è®º</th>
                            <th style="width:100px;">å½’ç±»</th>
                            <th style="width:70px;">æƒ…æ„Ÿ</th>
                            <th style="width:60px;">è¯­è¨€</th>
                            <th>ç®€è¦åˆ†æ</th>
                        </tr>
                    </thead>
                    <tbody>
                        {''.join(html_rows)}
                    </tbody>
                </table>
                """

                # ä¿å­˜ç»“æœç”¨äºå¯¼å‡º
                LATEST_ANALYSIS_RESULTS[session.get('session_id', 'default')] = all_results

                source_title = f"FB: {url[:15]}..."

            except Exception as e:
                error_msg = f"âŒ çˆ¬è™«ä»»åŠ¡å¤±è´¥: {str(e)}"
                logger.error(error_msg)
                import traceback
                traceback.print_exc()
                return jsonify({'result': error_msg})

        else:
            error_msg = "âŒ é”™è¯¯ï¼šè¯·æä¾›é“¾æ¥æˆ–æ–‡ä»¶"
            logger.error(error_msg)
            return jsonify({'result': error_msg})

        # ä¿å­˜å†å²è®°å½•
        save_history(source_title, result, 'sentiment')

        logger.info("âœ… èˆ†æƒ…åˆ†æå®Œæˆ")
        logger.info("=" * 60 + "\n")

        return jsonify({'result': result})

    except Exception as e:
        error_msg = f"âŒ ç³»ç»Ÿé”™è¯¯: {str(e)}"
        logger.error(error_msg)
        import traceback
        traceback.print_exc()
        return jsonify({'result': error_msg})

# ============================================
# åŠŸèƒ½ 2: ç«å“ç›‘æ§
# ============================================

@app.route('/competitor-tool')
def competitor_tool():
    """ç«å“ç›‘æ§å·¥å…·é¡µé¢"""
    if not session.get('logged_in'):
        return redirect(url_for('login'))
    return render_template('competitor.html')


@app.route('/monitor_competitors', methods=['POST'])
def monitor_competitors():
    """ç«å“ç›‘æ§ API"""
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“¥ æ”¶åˆ°ç«å“ç›‘æ§è¯·æ±‚")

    try:
        data = request.json
        target_url = data.get('competitor_name')
        start_dt_str = data.get('startDate')
        end_dt_str = data.get('endDate')

        logger.info(f"ğŸ¯ ç›®æ ‡ URL: {target_url}")
        logger.info(f"ğŸ“… æ—¶é—´æ®µ: {start_dt_str} ~ {end_dt_str}")

        if not apify_client:
            error_msg = "âŒ é”™è¯¯ï¼šAPIFY_TOKEN æœªé…ç½®ï¼Œæ— æ³•ä½¿ç”¨çˆ¬è™«åŠŸèƒ½"
            print(error_msg)
            return jsonify({'result': f"<div class='alert alert-danger'>{error_msg}</div>"})

        # 1. æ—¥æœŸè½¬æ¢
        target_start = datetime.datetime.strptime(start_dt_str, '%Y-%m-%d').date()
        target_end = datetime.datetime.strptime(end_dt_str, '%Y-%m-%d').date()
        logger.info(f"ğŸ“† è§£ææ—¥æœŸ: {target_start} ~ {target_end}")

        # 2. äº‘ç«¯æŠ“å–
        logger.info("ğŸ•µï¸ å¯åŠ¨ TikTok çˆ¬è™«...")
        run_input = {
            "profiles": [target_url],
            "resultsPerPage": 35,
            "oldestPostDate": start_dt_str,
            "shouldDownloadVideos": False
        }

        # ä½¿ç”¨ start() å¯åŠ¨çˆ¬è™«
        run = apify_client.actor("clockworks/tiktok-scraper").start(run_input=run_input)
        logger.info(f"âœ… çˆ¬è™«ä»»åŠ¡å·²å¯åŠ¨ï¼ŒRun ID: {run['id']}")

        # ç­‰å¾…çˆ¬è™«å®Œæˆï¼ˆæ­£ç¡®çš„å‚æ•°åï¼‰
        logger.info("â³ ç­‰å¾…çˆ¬è™«å®Œæˆ...")
        run = apify_client.run(run['id']).wait_for_finish(wait_secs=180)
        logger.info(f"âœ… çˆ¬è™«ä»»åŠ¡å®Œæˆï¼ŒçŠ¶æ€: {run['status']}")

        if run['status'] != 'SUCCEEDED':
            error_msg = f"âŒ çˆ¬è™«ä»»åŠ¡å¤±è´¥ï¼ŒçŠ¶æ€: {run['status']}"
            logger.error(error_msg)
            return jsonify({'result': f"<div class='alert alert-danger'>{error_msg}</div>"})

        items = apify_client.dataset(run["defaultDatasetId"]).list_items().items
        logger.info(f"ğŸ“¦ è·å–åˆ° {len(items)} æ¡åŸå§‹æ•°æ®")

        # 3. æœ¬åœ°æ—¶é—´è¿‡æ»¤
        cleaned = []
        for it in items:
            raw_date = it.get("createTimeISO")
            if not raw_date:
                continue

            post_dt = datetime.datetime.fromisoformat(raw_date.replace('Z', '+00:00')).date()

            if target_start <= post_dt <= target_end:
                cleaned.append({
                    "desc": it.get("desc", "æ— æè¿°"),
                    "likes": it.get("diggCount", 0),
                    "views": it.get("playCount", 0),
                    "comments": it.get("commentCount", 0),
                    "shares": it.get("shareCount", 0),
                    "collects": it.get("collectCount", 0),
                    "url": it.get("webVideoUrl"),
                    "date": str(post_dt)
                })

        logger.info(f"âœ… æ—¶é—´è¿‡æ»¤åå‰©ä½™ {len(cleaned)} æ¡æ•°æ®")

        if not cleaned:
            warning_msg = f"<div class='alert alert-warning'>åœ¨æ­¤æœŸé—´ ({start_dt_str} ~ {end_dt_str}) æœªå‘ç°è§†é¢‘ã€‚</div>"
            logger.info("âš ï¸ æœªå‘ç°ç¬¦åˆæ¡ä»¶çš„è§†é¢‘")
            return jsonify({'result': warning_msg})

        # 4. Gemini ç”ŸæˆæŠ¥å‘Š
        prompt = f"""
You are a Data Entry Assistant. Please fill the following TikTok data into the PROVIDED HTML TEMPLATE.

ã€Data Sourceã€‘: {cleaned}
ã€Periodã€‘: {start_dt_str} to {end_dt_str}

ã€STRICT TEMPLATE (Use this EXACT structure)ã€‘:
<div style="width:100%; font-family:sans-serif;">
    <h3 style="color:#D32F2F; border-bottom:2px solid #eee; padding-bottom:10px;">ğŸ“Š æ•°æ®æ¦‚è§ˆè¡¨ ({start_dt_str} è‡³ {end_dt_str})</h3>
    <table class="table" style="width:100%; margin-bottom:30px; text-align:center; font-size:0.9rem;">
        <tr style="background:#f8f9fa;">
            <th>æ€»æ’­æ”¾</th><th>æ€»äº’åŠ¨</th><th>æ€»ç‚¹èµ</th><th>æ€»è¯„è®º</th><th>æ€»æ”¶è—</th><th>æ€»è½¬å‘</th>
        </tr>
        <tr>
            <td>[æ€»æ’­æ”¾æ•°]</td><td>[æ€»äº’åŠ¨æ•°]</td><td>[æ€»ç‚¹èµæ•°]</td><td>[æ€»è¯„è®ºæ•°]</td><td>[æ€»æ”¶è—æ•°]</td><td>[æ€»è½¬å‘æ•°]</td>
        </tr>
    </table>

    <h3 style="color:#D32F2F; border-bottom:2px solid #eee; padding-bottom:10px;">ğŸ”¥ çˆ†æ¬¾è§†é¢‘ç²¾é€‰</h3>
    <div style="background:#FFF9F9; border-left:5px solid #D32F2F; padding:20px; margin-bottom:15px; border-radius:8px;">
        <p><strong>è§†é¢‘æè¿°ï¼š</strong> [æè¿°å†…å®¹]</p>
        <p><strong>æ ¸å¿ƒæŒ‡æ ‡ï¼š</strong> æ’­æ”¾: [æ’­æ”¾æ•°] | ç‚¹èµ: [ç‚¹èµæ•°] | äº’åŠ¨: [è¯„è®ºæ•°]è¯„è®º / [åˆ†äº«æ•°]åˆ†äº«</p>
        <p><strong>æŸ¥çœ‹è¯¦æƒ…ï¼š</strong> <a href="[webVideoUrl]" target="_blank" style="color:#2962FF;">ç‚¹å‡»è¿›å…¥ TikTok è§‚çœ‹åŸæ–‡é“¾æ¥</a></p>
    </div>
</div>

ã€Requirementsã€‘:
- å¿…é¡»ä½¿ç”¨ä¸­æ–‡å¡«å……æ¨¡æ¿ã€‚
- æ€»äº’åŠ¨ = ç‚¹èµ + è¯„è®º + æ”¶è— + è½¬å‘çš„æ€»å’Œã€‚
- ä¸¥ç¦æ·»åŠ æ¨¡æ¿ä¹‹å¤–çš„ä»»ä½•æ–‡å­—ï¼ˆåŒ…æ‹¬åˆ†æã€å»ºè®®ã€å‰è¨€ã€ç»“è¯­ï¼‰ã€‚
- ä»…è¾“å‡º Raw HTML ä»£ç ï¼Œç¦æ­¢ Markdown ä»£ç å—ã€‚
"""

        logger.info("ğŸ¤– å¼€å§‹è°ƒç”¨ Gemini API ç”ŸæˆæŠ¥å‘Š...")
        result = call_gemini(prompt)

        # æ¸…ç† Markdown ä»£ç å—æ ‡è®°
        result = result.replace('```html', '').replace('```', '').strip()

        # ä¿å­˜å†å²è®°å½•
        save_history(f"ç«å“æ•°æ®:{target_url[20:30]}", result, 'competitor')

        logger.info("âœ… ç«å“ç›‘æ§å®Œæˆ")
        logger.info("=" * 60 + "\n")

        return jsonify({'result': result})

    except Exception as e:
        error_msg = f"âŒ ç›‘æ§å¤±è´¥: {str(e)}"
        print(error_msg)
        import traceback
        traceback.print_exc()
        return jsonify({'result': f"<div class='alert alert-danger'>{error_msg}</div>"})

# ============================================
# åŠŸèƒ½ 3: è§†é¢‘ç”Ÿæˆ
# ============================================

@app.route('/video-tool')
def video_tool():
    """è§†é¢‘ç”Ÿæˆå·¥å…·é¡µé¢"""
    if not session.get('logged_in'):
        return redirect(url_for('login'))
    return render_template('video.html')


@app.route('/generate_video', methods=['POST'])
def generate_video():
    """è§†é¢‘ç”Ÿæˆ API"""
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“¥ æ”¶åˆ°è§†é¢‘ç”Ÿæˆè¯·æ±‚")

    try:
        prompt = request.json.get('prompt')
        logger.info(f"ğŸ¬ Prompt: {prompt[:50]}...")

        video_url = call_veo_api(prompt)
        save_history(f"è§†é¢‘: {prompt[:10]}", video_url, 'video')

        logger.info("âœ… è§†é¢‘ç”Ÿæˆå®Œæˆ")
        logger.info("=" * 60 + "\n")

        return jsonify({'video_url': video_url})

    except Exception as e:
        error_msg = f"âŒ è§†é¢‘ç”Ÿæˆå¤±è´¥: {str(e)}"
        print(error_msg)
        import traceback
        traceback.print_exc()
        return jsonify({'error': error_msg})

# ============================================
# å†å²è®°å½•ç®¡ç†
# ============================================

@app.route('/get_history')
def get_history():
    """è·å–å†å²è®°å½•"""
    return jsonify(HISTORY_DB[::-1])


@app.route('/get_record/<int:id>')
def get_record(id):
    """è·å–å•æ¡è®°å½•"""
    record = next((x for x in HISTORY_DB if x['id'] == id), None)
    return jsonify(record)

# ============================================
# Excel å¯¼å‡ºåŠŸèƒ½
# ============================================

def create_excel_by_language(results):
    """æŒ‰è¯­è¨€åˆ†ç±»ç”Ÿæˆ Excel"""
    wb = Workbook()
    wb.remove(wb.active)  # åˆ é™¤é»˜è®¤ sheet

    # æŒ‰è¯­è¨€åˆ†ç»„
    language_groups = {}
    for item in results:
        lang = item.get('language', 'å…¶ä»–')
        if lang not in language_groups:
            language_groups[lang] = []
        language_groups[lang].append(item)

    # ä¸ºæ¯ä¸ªè¯­è¨€åˆ›å»º Sheet
    for lang, items in sorted(language_groups.items()):
        ws = wb.create_sheet(title=lang)

        # è¡¨å¤´
        headers = ['åºå·', 'åŸå§‹è¯„è®º', 'å½’ç±»', 'æƒ…æ„Ÿå€¾å‘', 'è¯­è¨€', 'ç®€è¦åˆ†æ']
        ws.append(headers)

        # è®¾ç½®è¡¨å¤´æ ·å¼
        header_fill = PatternFill(start_color='4472C4', end_color='4472C4', fill_type='solid')
        header_font = Font(bold=True, color='FFFFFF')
        for cell in ws[1]:
            cell.fill = header_fill
            cell.font = header_font
            cell.alignment = Alignment(horizontal='center', vertical='center')

        # æ·»åŠ æ•°æ®
        for idx, item in enumerate(items, 1):
            ws.append([
                idx,
                item.get('text', ''),
                item.get('category', ''),
                item.get('sentiment', ''),
                item.get('language', ''),
                item.get('analysis', '')
            ])

        # è®¾ç½®åˆ—å®½
        ws.column_dimensions['A'].width = 8
        ws.column_dimensions['B'].width = 50
        ws.column_dimensions['C'].width = 20
        ws.column_dimensions['D'].width = 12
        ws.column_dimensions['E'].width = 10
        ws.column_dimensions['F'].width = 40

        # å†»ç»“é¦–è¡Œ
        ws.freeze_panes = 'A2'

    return wb


def create_excel_by_category(results):
    """æŒ‰åˆ†ç±»ç”Ÿæˆ Excel"""
    wb = Workbook()
    wb.remove(wb.active)

    # æŒ‰åˆ†ç±»åˆ†ç»„
    category_groups = {}
    for item in results:
        cat = item.get('category', 'å…¶ä»–')
        if cat not in category_groups:
            category_groups[cat] = []
        category_groups[cat].append(item)

    # åˆ†ç±»é¡ºåº
    category_order = ['å¤–æŒ‚ä½œå¼Š', 'æ¸¸æˆä¼˜åŒ–', 'æ¸¸æˆBug', 'å……å€¼é€€æ¬¾', 'æ–°æ¨¡å¼/åœ°å›¾/å¹³è¡¡æ€§å»ºè®®']

    # ä¸ºæ¯ä¸ªåˆ†ç±»åˆ›å»º Sheet
    for cat in category_order:
        if cat not in category_groups:
            continue

        items = category_groups[cat]
        ws = wb.create_sheet(title=cat)

        # è¡¨å¤´
        headers = ['åºå·', 'åŸå§‹è¯„è®º', 'å½’ç±»', 'æƒ…æ„Ÿå€¾å‘', 'è¯­è¨€', 'ç®€è¦åˆ†æ']
        ws.append(headers)

        # è®¾ç½®è¡¨å¤´æ ·å¼
        header_fill = PatternFill(start_color='D32F2F', end_color='D32F2F', fill_type='solid')
        header_font = Font(bold=True, color='FFFFFF')
        for cell in ws[1]:
            cell.fill = header_fill
            cell.font = header_font
            cell.alignment = Alignment(horizontal='center', vertical='center')

        # æ·»åŠ æ•°æ®
        for idx, item in enumerate(items, 1):
            ws.append([
                idx,
                item.get('text', ''),
                item.get('category', ''),
                item.get('sentiment', ''),
                item.get('language', ''),
                item.get('analysis', '')
            ])

        # è®¾ç½®åˆ—å®½
        ws.column_dimensions['A'].width = 8
        ws.column_dimensions['B'].width = 50
        ws.column_dimensions['C'].width = 20
        ws.column_dimensions['D'].width = 12
        ws.column_dimensions['E'].width = 10
        ws.column_dimensions['F'].width = 40

        # å†»ç»“é¦–è¡Œ
        ws.freeze_panes = 'A2'

    return wb


@app.route('/export_by_language')
def export_by_language():
    """æŒ‰è¯­è¨€å¯¼å‡º Excel"""
    if not session.get('logged_in'):
        return redirect(url_for('login'))

    session_id = session.get('session_id', 'default')
    results = LATEST_ANALYSIS_RESULTS.get(session_id, [])

    if not results:
        return jsonify({'error': 'æ²¡æœ‰å¯å¯¼å‡ºçš„æ•°æ®'}), 400

    try:
        wb = create_excel_by_language(results)

        # ç”Ÿæˆæ–‡ä»¶
        output = BytesIO()
        wb.save(output)
        output.seek(0)

        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M')
        filename = f'è¯­è¨€åˆ†ç±»æŠ¥å‘Š_{timestamp}.xlsx'

        logger.info(f"ğŸ“¥ å¯¼å‡ºè¯­è¨€åˆ†ç±»æŠ¥å‘Š: {len(results)} æ¡æ•°æ®")

        return send_file(
            output,
            mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            as_attachment=True,
            download_name=filename
        )
    except Exception as e:
        logger.error(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/export_by_category')
def export_by_category():
    """æŒ‰åˆ†ç±»å¯¼å‡º Excel"""
    if not session.get('logged_in'):
        return redirect(url_for('login'))

    session_id = session.get('session_id', 'default')
    results = LATEST_ANALYSIS_RESULTS.get(session_id, [])

    if not results:
        return jsonify({'error': 'æ²¡æœ‰å¯å¯¼å‡ºçš„æ•°æ®'}), 400

    try:
        wb = create_excel_by_category(results)

        # ç”Ÿæˆæ–‡ä»¶
        output = BytesIO()
        wb.save(output)
        output.seek(0)

        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M')
        filename = f'é—®é¢˜åˆ†ç±»æŠ¥å‘Š_{timestamp}.xlsx'

        logger.info(f"ğŸ“¥ å¯¼å‡ºé—®é¢˜åˆ†ç±»æŠ¥å‘Š: {len(results)} æ¡æ•°æ®")

        return send_file(
            output,
            mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            as_attachment=True,
            download_name=filename
        )
    except Exception as e:
        logger.error(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

# ============================================
# åº”ç”¨å¯åŠ¨
# ============================================

if __name__ == '__main__':
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ‰ Sailson AI å·¥ä½œå°å·²å¯åŠ¨")
    logger.info(f"ğŸŒ è®¿é—®åœ°å€: http://0.0.0.0:{PORT}")
    logger.info("=" * 60 + "\n")

    app.run(debug=False, host='0.0.0.0', port=PORT)
